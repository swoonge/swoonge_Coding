{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN신경망\n",
    "\n",
    "![Alt text](ResNet_Architectures.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    -in_placnes: in_channels\n",
    "    -out_placnes: out_channels\n",
    "    -bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d에서는 bias=False로 설정\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3, # 여기가 conv3x3 고정\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups, # 이건 뭘까\n",
    "        bias=False, # BatchNorm에 bias가 포함되어 있으므로, conv2d에서는 bias=False로 설정\n",
    "        dilation=dilation,\n",
    "    ) # padding과 dilation이 같은 값으로 되어있는 이유 -> dilation이 1 커질 때 마다 실질적인 conv이 보는 크기(ex커널사이즈)가 5x5, 7x7 영역 등으로 커지기 때문에 동일한 크기의 패딩이 필요\n",
    "\n",
    "# 차원 맞춰주기 용\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d: # inputdim -> outputdim // stride 는 크기 줄일때\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False) # conv1x1인데, 보틀넥에서 사용되는 듯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 점선 화살표 부분 맞춰는 코드\n",
    "        # stride가 1이 아니거나(outplane이 /2로 작아지거나) or in_channel이 out_channel*expansion()\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.inplanes),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        # self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
    "\n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        # x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# def resnet18():\n",
    "#     return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "# def resnet34():\n",
    "#     return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4 + 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8 + 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]           4,096\n",
      "       BatchNorm2d-5           [-1, 64, 16, 16]             128\n",
      "              ReLU-6           [-1, 64, 16, 16]               0\n",
      "            Conv2d-7           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 16, 16]             128\n",
      "              ReLU-9           [-1, 64, 16, 16]               0\n",
      "           Conv2d-10          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-11          [-1, 256, 16, 16]             512\n",
      "           Conv2d-12          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-13          [-1, 256, 16, 16]             512\n",
      "             ReLU-14          [-1, 256, 16, 16]               0\n",
      "       BottleNeck-15          [-1, 256, 16, 16]               0\n",
      "           Conv2d-16           [-1, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-17           [-1, 64, 16, 16]             128\n",
      "             ReLU-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 16, 16]             128\n",
      "             ReLU-21           [-1, 64, 16, 16]               0\n",
      "           Conv2d-22          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-23          [-1, 256, 16, 16]             512\n",
      "             ReLU-24          [-1, 256, 16, 16]               0\n",
      "       BottleNeck-25          [-1, 256, 16, 16]               0\n",
      "           Conv2d-26           [-1, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-27           [-1, 64, 16, 16]             128\n",
      "             ReLU-28           [-1, 64, 16, 16]               0\n",
      "           Conv2d-29           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-30           [-1, 64, 16, 16]             128\n",
      "             ReLU-31           [-1, 64, 16, 16]               0\n",
      "           Conv2d-32          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-33          [-1, 256, 16, 16]             512\n",
      "             ReLU-34          [-1, 256, 16, 16]               0\n",
      "       BottleNeck-35          [-1, 256, 16, 16]               0\n",
      "           Conv2d-36          [-1, 128, 16, 16]          32,768\n",
      "      BatchNorm2d-37          [-1, 128, 16, 16]             256\n",
      "             ReLU-38          [-1, 128, 16, 16]               0\n",
      "           Conv2d-39            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-40            [-1, 128, 8, 8]             256\n",
      "             ReLU-41            [-1, 128, 8, 8]               0\n",
      "           Conv2d-42            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-43            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-44            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-45            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-46            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-47            [-1, 512, 8, 8]               0\n",
      "           Conv2d-48            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-49            [-1, 128, 8, 8]             256\n",
      "             ReLU-50            [-1, 128, 8, 8]               0\n",
      "           Conv2d-51            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-52            [-1, 128, 8, 8]             256\n",
      "             ReLU-53            [-1, 128, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-56            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-57            [-1, 512, 8, 8]               0\n",
      "           Conv2d-58            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-59            [-1, 128, 8, 8]             256\n",
      "             ReLU-60            [-1, 128, 8, 8]               0\n",
      "           Conv2d-61            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-62            [-1, 128, 8, 8]             256\n",
      "             ReLU-63            [-1, 128, 8, 8]               0\n",
      "           Conv2d-64            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-65            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-66            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-67            [-1, 512, 8, 8]               0\n",
      "           Conv2d-68            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-69            [-1, 128, 8, 8]             256\n",
      "             ReLU-70            [-1, 128, 8, 8]               0\n",
      "           Conv2d-71            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-72            [-1, 128, 8, 8]             256\n",
      "             ReLU-73            [-1, 128, 8, 8]               0\n",
      "           Conv2d-74            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-75            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-76            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-77            [-1, 512, 8, 8]               0\n",
      "           Conv2d-78            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-79            [-1, 128, 8, 8]             256\n",
      "             ReLU-80            [-1, 128, 8, 8]               0\n",
      "           Conv2d-81            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-82            [-1, 128, 8, 8]             256\n",
      "             ReLU-83            [-1, 128, 8, 8]               0\n",
      "           Conv2d-84            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-85            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-86            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-87            [-1, 512, 8, 8]               0\n",
      "           Conv2d-88            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-89            [-1, 128, 8, 8]             256\n",
      "             ReLU-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-92            [-1, 128, 8, 8]             256\n",
      "             ReLU-93            [-1, 128, 8, 8]               0\n",
      "           Conv2d-94            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-95            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-96            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-97            [-1, 512, 8, 8]               0\n",
      "           Conv2d-98            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-99            [-1, 128, 8, 8]             256\n",
      "            ReLU-100            [-1, 128, 8, 8]               0\n",
      "          Conv2d-101            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-102            [-1, 128, 8, 8]             256\n",
      "            ReLU-103            [-1, 128, 8, 8]               0\n",
      "          Conv2d-104            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-105            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-106            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-107            [-1, 512, 8, 8]               0\n",
      "          Conv2d-108            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-109            [-1, 128, 8, 8]             256\n",
      "            ReLU-110            [-1, 128, 8, 8]               0\n",
      "          Conv2d-111            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-112            [-1, 128, 8, 8]             256\n",
      "            ReLU-113            [-1, 128, 8, 8]               0\n",
      "          Conv2d-114            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-115            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-116            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-117            [-1, 512, 8, 8]               0\n",
      "          Conv2d-118            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-119            [-1, 128, 8, 8]             256\n",
      "            ReLU-120            [-1, 128, 8, 8]               0\n",
      "          Conv2d-121            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-122            [-1, 128, 8, 8]             256\n",
      "            ReLU-123            [-1, 128, 8, 8]               0\n",
      "          Conv2d-124            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-125            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-126            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-127            [-1, 512, 8, 8]               0\n",
      "          Conv2d-128            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-129            [-1, 128, 8, 8]             256\n",
      "            ReLU-130            [-1, 128, 8, 8]               0\n",
      "          Conv2d-131            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-132            [-1, 128, 8, 8]             256\n",
      "            ReLU-133            [-1, 128, 8, 8]               0\n",
      "          Conv2d-134            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-135            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-136            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-137            [-1, 512, 8, 8]               0\n",
      "          Conv2d-138            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-139            [-1, 128, 8, 8]             256\n",
      "            ReLU-140            [-1, 128, 8, 8]               0\n",
      "          Conv2d-141            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-142            [-1, 128, 8, 8]             256\n",
      "            ReLU-143            [-1, 128, 8, 8]               0\n",
      "          Conv2d-144            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-146            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-147            [-1, 512, 8, 8]               0\n",
      "          Conv2d-148            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-149            [-1, 128, 8, 8]             256\n",
      "            ReLU-150            [-1, 128, 8, 8]               0\n",
      "          Conv2d-151            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-152            [-1, 128, 8, 8]             256\n",
      "            ReLU-153            [-1, 128, 8, 8]               0\n",
      "          Conv2d-154            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-155            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-156            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-157            [-1, 512, 8, 8]               0\n",
      "          Conv2d-158            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-159            [-1, 128, 8, 8]             256\n",
      "            ReLU-160            [-1, 128, 8, 8]               0\n",
      "          Conv2d-161            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-162            [-1, 128, 8, 8]             256\n",
      "            ReLU-163            [-1, 128, 8, 8]               0\n",
      "          Conv2d-164            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-165            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-166            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-167            [-1, 512, 8, 8]               0\n",
      "          Conv2d-168            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-169            [-1, 128, 8, 8]             256\n",
      "            ReLU-170            [-1, 128, 8, 8]               0\n",
      "          Conv2d-171            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-172            [-1, 128, 8, 8]             256\n",
      "            ReLU-173            [-1, 128, 8, 8]               0\n",
      "          Conv2d-174            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-175            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-176            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-177            [-1, 512, 8, 8]               0\n",
      "          Conv2d-178            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-179            [-1, 128, 8, 8]             256\n",
      "            ReLU-180            [-1, 128, 8, 8]               0\n",
      "          Conv2d-181            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-182            [-1, 128, 8, 8]             256\n",
      "            ReLU-183            [-1, 128, 8, 8]               0\n",
      "          Conv2d-184            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-185            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-186            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-187            [-1, 512, 8, 8]               0\n",
      "          Conv2d-188            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-189            [-1, 128, 8, 8]             256\n",
      "            ReLU-190            [-1, 128, 8, 8]               0\n",
      "          Conv2d-191            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-192            [-1, 128, 8, 8]             256\n",
      "            ReLU-193            [-1, 128, 8, 8]               0\n",
      "          Conv2d-194            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-195            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-196            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-197            [-1, 512, 8, 8]               0\n",
      "          Conv2d-198            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-199            [-1, 128, 8, 8]             256\n",
      "            ReLU-200            [-1, 128, 8, 8]               0\n",
      "          Conv2d-201            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-202            [-1, 128, 8, 8]             256\n",
      "            ReLU-203            [-1, 128, 8, 8]               0\n",
      "          Conv2d-204            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-205            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-206            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-207            [-1, 512, 8, 8]               0\n",
      "          Conv2d-208            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-209            [-1, 128, 8, 8]             256\n",
      "            ReLU-210            [-1, 128, 8, 8]               0\n",
      "          Conv2d-211            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-212            [-1, 128, 8, 8]             256\n",
      "            ReLU-213            [-1, 128, 8, 8]               0\n",
      "          Conv2d-214            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-215            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-216            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-217            [-1, 512, 8, 8]               0\n",
      "          Conv2d-218            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-219            [-1, 128, 8, 8]             256\n",
      "            ReLU-220            [-1, 128, 8, 8]               0\n",
      "          Conv2d-221            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-222            [-1, 128, 8, 8]             256\n",
      "            ReLU-223            [-1, 128, 8, 8]               0\n",
      "          Conv2d-224            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-225            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-226            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-227            [-1, 512, 8, 8]               0\n",
      "          Conv2d-228            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-229            [-1, 128, 8, 8]             256\n",
      "            ReLU-230            [-1, 128, 8, 8]               0\n",
      "          Conv2d-231            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-232            [-1, 128, 8, 8]             256\n",
      "            ReLU-233            [-1, 128, 8, 8]               0\n",
      "          Conv2d-234            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-235            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-236            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-237            [-1, 512, 8, 8]               0\n",
      "          Conv2d-238            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-239            [-1, 128, 8, 8]             256\n",
      "            ReLU-240            [-1, 128, 8, 8]               0\n",
      "          Conv2d-241            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-242            [-1, 128, 8, 8]             256\n",
      "            ReLU-243            [-1, 128, 8, 8]               0\n",
      "          Conv2d-244            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-245            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-246            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-247            [-1, 512, 8, 8]               0\n",
      "          Conv2d-248            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-249            [-1, 128, 8, 8]             256\n",
      "            ReLU-250            [-1, 128, 8, 8]               0\n",
      "          Conv2d-251            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-252            [-1, 128, 8, 8]             256\n",
      "            ReLU-253            [-1, 128, 8, 8]               0\n",
      "          Conv2d-254            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-255            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-256            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-257            [-1, 512, 8, 8]               0\n",
      "          Conv2d-258            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-259            [-1, 128, 8, 8]             256\n",
      "            ReLU-260            [-1, 128, 8, 8]               0\n",
      "          Conv2d-261            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-262            [-1, 128, 8, 8]             256\n",
      "            ReLU-263            [-1, 128, 8, 8]               0\n",
      "          Conv2d-264            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-265            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-266            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-267            [-1, 512, 8, 8]               0\n",
      "          Conv2d-268            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-269            [-1, 128, 8, 8]             256\n",
      "            ReLU-270            [-1, 128, 8, 8]               0\n",
      "          Conv2d-271            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-272            [-1, 128, 8, 8]             256\n",
      "            ReLU-273            [-1, 128, 8, 8]               0\n",
      "          Conv2d-274            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-275            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-276            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-277            [-1, 512, 8, 8]               0\n",
      "          Conv2d-278            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-279            [-1, 128, 8, 8]             256\n",
      "            ReLU-280            [-1, 128, 8, 8]               0\n",
      "          Conv2d-281            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-282            [-1, 128, 8, 8]             256\n",
      "            ReLU-283            [-1, 128, 8, 8]               0\n",
      "          Conv2d-284            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-285            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-286            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-287            [-1, 512, 8, 8]               0\n",
      "          Conv2d-288            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-289            [-1, 128, 8, 8]             256\n",
      "            ReLU-290            [-1, 128, 8, 8]               0\n",
      "          Conv2d-291            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-292            [-1, 128, 8, 8]             256\n",
      "            ReLU-293            [-1, 128, 8, 8]               0\n",
      "          Conv2d-294            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-295            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-296            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-297            [-1, 512, 8, 8]               0\n",
      "          Conv2d-298            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-299            [-1, 128, 8, 8]             256\n",
      "            ReLU-300            [-1, 128, 8, 8]               0\n",
      "          Conv2d-301            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-302            [-1, 128, 8, 8]             256\n",
      "            ReLU-303            [-1, 128, 8, 8]               0\n",
      "          Conv2d-304            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-305            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-306            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-307            [-1, 512, 8, 8]               0\n",
      "          Conv2d-308            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-309            [-1, 128, 8, 8]             256\n",
      "            ReLU-310            [-1, 128, 8, 8]               0\n",
      "          Conv2d-311            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-312            [-1, 128, 8, 8]             256\n",
      "            ReLU-313            [-1, 128, 8, 8]               0\n",
      "          Conv2d-314            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-315            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-316            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-317            [-1, 512, 8, 8]               0\n",
      "          Conv2d-318            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-319            [-1, 128, 8, 8]             256\n",
      "            ReLU-320            [-1, 128, 8, 8]               0\n",
      "          Conv2d-321            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-322            [-1, 128, 8, 8]             256\n",
      "            ReLU-323            [-1, 128, 8, 8]               0\n",
      "          Conv2d-324            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-325            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-326            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-327            [-1, 512, 8, 8]               0\n",
      "          Conv2d-328            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-329            [-1, 128, 8, 8]             256\n",
      "            ReLU-330            [-1, 128, 8, 8]               0\n",
      "          Conv2d-331            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-332            [-1, 128, 8, 8]             256\n",
      "            ReLU-333            [-1, 128, 8, 8]               0\n",
      "          Conv2d-334            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-335            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-336            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-337            [-1, 512, 8, 8]               0\n",
      "          Conv2d-338            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-339            [-1, 128, 8, 8]             256\n",
      "            ReLU-340            [-1, 128, 8, 8]               0\n",
      "          Conv2d-341            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-342            [-1, 128, 8, 8]             256\n",
      "            ReLU-343            [-1, 128, 8, 8]               0\n",
      "          Conv2d-344            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-345            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-346            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-347            [-1, 512, 8, 8]               0\n",
      "          Conv2d-348            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-349            [-1, 128, 8, 8]             256\n",
      "            ReLU-350            [-1, 128, 8, 8]               0\n",
      "          Conv2d-351            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-352            [-1, 128, 8, 8]             256\n",
      "            ReLU-353            [-1, 128, 8, 8]               0\n",
      "          Conv2d-354            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-355            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-356            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-357            [-1, 512, 8, 8]               0\n",
      "          Conv2d-358            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-359            [-1, 128, 8, 8]             256\n",
      "            ReLU-360            [-1, 128, 8, 8]               0\n",
      "          Conv2d-361            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-362            [-1, 128, 8, 8]             256\n",
      "            ReLU-363            [-1, 128, 8, 8]               0\n",
      "          Conv2d-364            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-365            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-366            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-367            [-1, 512, 8, 8]               0\n",
      "          Conv2d-368            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-369            [-1, 128, 8, 8]             256\n",
      "            ReLU-370            [-1, 128, 8, 8]               0\n",
      "          Conv2d-371            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-372            [-1, 128, 8, 8]             256\n",
      "            ReLU-373            [-1, 128, 8, 8]               0\n",
      "          Conv2d-374            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-375            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-376            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-377            [-1, 512, 8, 8]               0\n",
      "          Conv2d-378            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-379            [-1, 128, 8, 8]             256\n",
      "            ReLU-380            [-1, 128, 8, 8]               0\n",
      "          Conv2d-381            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-382            [-1, 128, 8, 8]             256\n",
      "            ReLU-383            [-1, 128, 8, 8]               0\n",
      "          Conv2d-384            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-385            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-386            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-387            [-1, 512, 8, 8]               0\n",
      "          Conv2d-388            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-389            [-1, 128, 8, 8]             256\n",
      "            ReLU-390            [-1, 128, 8, 8]               0\n",
      "          Conv2d-391            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-392            [-1, 128, 8, 8]             256\n",
      "            ReLU-393            [-1, 128, 8, 8]               0\n",
      "          Conv2d-394            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-395            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-396            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-397            [-1, 512, 8, 8]               0\n",
      "          Conv2d-398            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-399            [-1, 128, 8, 8]             256\n",
      "            ReLU-400            [-1, 128, 8, 8]               0\n",
      "          Conv2d-401            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-402            [-1, 128, 8, 8]             256\n",
      "            ReLU-403            [-1, 128, 8, 8]               0\n",
      "          Conv2d-404            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-405            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-406            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-407            [-1, 512, 8, 8]               0\n",
      "          Conv2d-408            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-409            [-1, 128, 8, 8]             256\n",
      "            ReLU-410            [-1, 128, 8, 8]               0\n",
      "          Conv2d-411            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-412            [-1, 128, 8, 8]             256\n",
      "            ReLU-413            [-1, 128, 8, 8]               0\n",
      "          Conv2d-414            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-415            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-416            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-417            [-1, 512, 8, 8]               0\n",
      "          Conv2d-418            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-419            [-1, 128, 8, 8]             256\n",
      "            ReLU-420            [-1, 128, 8, 8]               0\n",
      "          Conv2d-421            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-422            [-1, 128, 8, 8]             256\n",
      "            ReLU-423            [-1, 128, 8, 8]               0\n",
      "          Conv2d-424            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-425            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-426            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-427            [-1, 512, 8, 8]               0\n",
      "          Conv2d-428            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-429            [-1, 128, 8, 8]             256\n",
      "            ReLU-430            [-1, 128, 8, 8]               0\n",
      "          Conv2d-431            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-432            [-1, 128, 8, 8]             256\n",
      "            ReLU-433            [-1, 128, 8, 8]               0\n",
      "          Conv2d-434            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-435            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-436            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-437            [-1, 512, 8, 8]               0\n",
      "          Conv2d-438            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-439            [-1, 128, 8, 8]             256\n",
      "            ReLU-440            [-1, 128, 8, 8]               0\n",
      "          Conv2d-441            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-442            [-1, 128, 8, 8]             256\n",
      "            ReLU-443            [-1, 128, 8, 8]               0\n",
      "          Conv2d-444            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-445            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-446            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-447            [-1, 512, 8, 8]               0\n",
      "          Conv2d-448            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-449            [-1, 128, 8, 8]             256\n",
      "            ReLU-450            [-1, 128, 8, 8]               0\n",
      "          Conv2d-451            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-452            [-1, 128, 8, 8]             256\n",
      "            ReLU-453            [-1, 128, 8, 8]               0\n",
      "          Conv2d-454            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-455            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-456            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-457            [-1, 512, 8, 8]               0\n",
      "          Conv2d-458            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-459            [-1, 128, 8, 8]             256\n",
      "            ReLU-460            [-1, 128, 8, 8]               0\n",
      "          Conv2d-461            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-462            [-1, 128, 8, 8]             256\n",
      "            ReLU-463            [-1, 128, 8, 8]               0\n",
      "          Conv2d-464            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-465            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-466            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-467            [-1, 512, 8, 8]               0\n",
      "          Conv2d-468            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-469            [-1, 128, 8, 8]             256\n",
      "            ReLU-470            [-1, 128, 8, 8]               0\n",
      "          Conv2d-471            [-1, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-472            [-1, 128, 8, 8]             256\n",
      "            ReLU-473            [-1, 128, 8, 8]               0\n",
      "          Conv2d-474            [-1, 512, 8, 8]          65,536\n",
      "     BatchNorm2d-475            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-476            [-1, 512, 8, 8]               0\n",
      "      BottleNeck-477            [-1, 512, 8, 8]               0\n",
      "          Conv2d-478            [-1, 256, 8, 8]         131,072\n",
      "     BatchNorm2d-479            [-1, 256, 8, 8]             512\n",
      "            ReLU-480            [-1, 256, 8, 8]               0\n",
      "          Conv2d-481            [-1, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-482            [-1, 256, 4, 4]             512\n",
      "            ReLU-483            [-1, 256, 4, 4]               0\n",
      "          Conv2d-484           [-1, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-485           [-1, 1024, 4, 4]           2,048\n",
      "          Conv2d-486           [-1, 1024, 4, 4]         524,288\n",
      "     BatchNorm2d-487           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-488           [-1, 1024, 4, 4]               0\n",
      "      BottleNeck-489           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-490            [-1, 256, 4, 4]         262,144\n",
      "     BatchNorm2d-491            [-1, 256, 4, 4]             512\n",
      "            ReLU-492            [-1, 256, 4, 4]               0\n",
      "          Conv2d-493            [-1, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-494            [-1, 256, 4, 4]             512\n",
      "            ReLU-495            [-1, 256, 4, 4]               0\n",
      "          Conv2d-496           [-1, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-497           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-498           [-1, 1024, 4, 4]               0\n",
      "      BottleNeck-499           [-1, 1024, 4, 4]               0\n",
      "          Conv2d-500            [-1, 256, 4, 4]         262,144\n",
      "     BatchNorm2d-501            [-1, 256, 4, 4]             512\n",
      "            ReLU-502            [-1, 256, 4, 4]               0\n",
      "          Conv2d-503            [-1, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-504            [-1, 256, 4, 4]             512\n",
      "            ReLU-505            [-1, 256, 4, 4]               0\n",
      "          Conv2d-506           [-1, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-507           [-1, 1024, 4, 4]           2,048\n",
      "            ReLU-508           [-1, 1024, 4, 4]               0\n",
      "      BottleNeck-509           [-1, 1024, 4, 4]               0\n",
      "AdaptiveAvgPool2d-510           [-1, 1024, 1, 1]               0\n",
      "          Linear-511                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 16,404,554\n",
      "Trainable params: 16,404,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 73.79\n",
      "Params size (MB): 62.58\n",
      "Estimated Total Size (MB): 136.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = resnet152().to(device)\n",
    "x = torch.randn(3, 3, 32, 32).to(device)\n",
    "output = model(x)\n",
    "print(output.size())\n",
    "summary(model, (3, 32, 32), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_train=datasets.CIFAR10(\"../DataSets/\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "CIFAR10_test=datasets.CIFAR10(\"../DataSets/\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(CIFAR10_train, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(CIFAR10_test, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=resnet152().to(device=device)\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_array = []\n",
    "accuracy_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for img, label in test_loader:\n",
    "          x = img.to(device)\n",
    "          y_ = label.to(device)\n",
    "\n",
    "          output = model.forward(x)\n",
    "          _, output_index = torch.max(output, 1)\n",
    "\n",
    "          total += label.size(0)\n",
    "          correct += (output_index == y_).sum().float()\n",
    "\n",
    "      print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
    "      return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 is start\n",
      "Accuracy of Test Data: 11.934621810913086\n",
      "Accuracy of Test Data: 16.22121810913086\n",
      "Accuracy of Test Data: 19.058387756347656\n",
      "Accuracy of Test Data: 23.5814151763916\n",
      "Accuracy of Test Data: 26.778371810913086\n",
      "Accuracy of Test Data: 27.672697067260742\n",
      "Accuracy of Test Data: 29.6361026763916\n",
      "Accuracy of Test Data: 31.229440689086914\n",
      "Accuracy of Test Data: 31.74342155456543\n",
      "Accuracy of Test Data: 34.54975509643555\n",
      "tensor(1.8245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "epoch 1 is start\n",
      "Accuracy of Test Data: 34.436676025390625\n",
      "Accuracy of Test Data: 36.86266326904297\n",
      "Accuracy of Test Data: 36.96546173095703\n",
      "Accuracy of Test Data: 37.87006759643555\n",
      "Accuracy of Test Data: 39.05221939086914\n",
      "Accuracy of Test Data: 38.46628189086914\n",
      "Accuracy of Test Data: 39.85403060913086\n",
      "Accuracy of Test Data: 38.394325256347656\n",
      "Accuracy of Test Data: 40.1418571472168\n",
      "Accuracy of Test Data: 40.152137756347656\n",
      "tensor(1.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "epoch 2 is start\n",
      "Accuracy of Test Data: 40.79975509643555\n",
      "Accuracy of Test Data: 41.683799743652344\n",
      "Accuracy of Test Data: 41.529605865478516\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m, i, \u001b[39m\"\u001b[39m\u001b[39mis start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m j, [img, label] \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m----> 4\u001b[0m     x \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      5\u001b[0m     y_ \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    print(\"epoch\", i, \"is start\")\n",
    "    for j, [img, label] in enumerate(train_loader):\n",
    "        x = img.to(device)\n",
    "        y_ = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output= model.forward(x)\n",
    "        loss = loss_func(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if j % 30 == 0:\n",
    "            loss_array.append(loss.cpu().detach().numpy())\n",
    "            accuracy_array.append(get_accuracy())\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_array[:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 21.741365432739258\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        x = img.to(device)\n",
    "        y_ = label.to(device)\n",
    "\n",
    "        output = model.forward(x)\n",
    "        _, output_index = torch.max(output, 1)\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += (output_index == y_).sum().float()\n",
    "\n",
    "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7350abcaff91871cc2fda5041ddf4038d94572c9fca8856fb0fc40a5853d68d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
