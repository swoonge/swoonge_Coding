{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.init as init\n",
    "\n",
    "# import scipy\n",
    "\n",
    "# 추가적인 모듈\n",
    "import torchvision\n",
    "# import torchvision.datasets as dset # vision 데이터를 읽어오는 역할\n",
    "# import torchvision.transforms as transforms # 이미지를 필요에 따라 변환해주는 역할을 하는 모듈\n",
    "from torch.utils import data # Data의 batch size 설정 및 random하게 섞기 등을 해주는 모듈\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0002\n",
    "num_epoch = 30\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    torchvision.transforms.ToTensor(),  # convert image to Tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=torchvision.datasets.MNIST(\"../DataSets/\", train=True, transform=torchvision.transforms.ToTensor(), target_transform=None, download=True)\n",
    "test_data=torchvision.datasets.MNIST(\"../DataSets/\", train=False, transform=torchvision.transforms.ToTensor(), target_transform=None, download=True)\n",
    "\n",
    "dataset_size = len(train_data)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = int(20)\n",
    "validation_size = dataset_size - train_size - test_size\n",
    "\n",
    "train_dataset, val_dataset, train_test = data.random_split(train_data, [train_size, validation_size, test_size])\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6, drop_last=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=6, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../DataSets/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "torch.Size([1, 28, 28])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f0e1ec50be0>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(train_data[0][0].shape)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 점선 화살표 부분 맞춰는 코드\n",
    "        # stride가 1이 아니거나(outplane이 /2로 작아지거나) or in_channel이 out_channel*expansion()\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResCRNN(nn.Module):\n",
    "    def __init__(self, num_block: int = [3, 3], num_classes: int = 10, init_weights: bool = True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.inplanes),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(BottleNeck, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(BottleNeck, 128, num_block[1], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(128 * BottleNeck.expansion, num_classes)\n",
    "\n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inplanes, out_channels, stride))\n",
    "            self.inplanes = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]             576\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "           Conv2d-11          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 16, 16]             512\n",
      "           Conv2d-13          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 16, 16]             512\n",
      "             ReLU-15          [-1, 256, 16, 16]               0\n",
      "       BottleNeck-16          [-1, 256, 16, 16]               0\n",
      "           Conv2d-17           [-1, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 16, 16]             128\n",
      "             ReLU-19           [-1, 64, 16, 16]               0\n",
      "           Conv2d-20           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 16, 16]             128\n",
      "             ReLU-22           [-1, 64, 16, 16]               0\n",
      "           Conv2d-23          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 16, 16]             512\n",
      "             ReLU-25          [-1, 256, 16, 16]               0\n",
      "       BottleNeck-26          [-1, 256, 16, 16]               0\n",
      "           Conv2d-27           [-1, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
      "             ReLU-29           [-1, 64, 16, 16]               0\n",
      "           Conv2d-30           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 16, 16]             128\n",
      "             ReLU-32           [-1, 64, 16, 16]               0\n",
      "           Conv2d-33          [-1, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 16, 16]             512\n",
      "             ReLU-35          [-1, 256, 16, 16]               0\n",
      "       BottleNeck-36          [-1, 256, 16, 16]               0\n",
      "           Conv2d-37          [-1, 128, 16, 16]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "             ReLU-39          [-1, 128, 16, 16]               0\n",
      "           Conv2d-40            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 8, 8]             256\n",
      "             ReLU-42            [-1, 128, 8, 8]               0\n",
      "           Conv2d-43            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-45            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-47            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-48            [-1, 512, 8, 8]               0\n",
      "           Conv2d-49            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 8, 8]             256\n",
      "             ReLU-51            [-1, 128, 8, 8]               0\n",
      "           Conv2d-52            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 8, 8]             256\n",
      "             ReLU-54            [-1, 128, 8, 8]               0\n",
      "           Conv2d-55            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-57            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-58            [-1, 512, 8, 8]               0\n",
      "           Conv2d-59            [-1, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 8, 8]             256\n",
      "             ReLU-61            [-1, 128, 8, 8]               0\n",
      "           Conv2d-62            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 8, 8]             256\n",
      "             ReLU-64            [-1, 128, 8, 8]               0\n",
      "           Conv2d-65            [-1, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-67            [-1, 512, 8, 8]               0\n",
      "       BottleNeck-68            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-69            [-1, 512, 1, 1]               0\n",
      "           Linear-70                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 1,161,162\n",
      "Trainable params: 1,161,162\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 16.07\n",
      "Params size (MB): 4.43\n",
      "Estimated Total Size (MB): 20.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = ResCRNN([3, 3]).to(device)\n",
    "\n",
    "# 모델이 잘 통과하는지 확인\n",
    "x = torch.randn(1, 1, 32, 32).to(device)\n",
    "output = resnet(x)\n",
    "print(output.size())\n",
    "\n",
    "# 모델 summary\n",
    "torchsummary.summary(resnet, (1, 32, 32), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResCRNN([3,3]).to(device)\n",
    "\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_array = []\n",
    "accuracy_array = []\n",
    "\n",
    "test_model_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      val_datas = train_test if  test_model_flag is True else test_loader\n",
    "      for img, label in val_datas:\n",
    "          x = img.to(device)\n",
    "          y_ = label.to(device)\n",
    "\n",
    "          output = model.forward(x)\n",
    "          _, output_index = torch.max(output, 1)\n",
    "\n",
    "          total += label.size(0)\n",
    "          correct += (output_index == y_).sum().float()\n",
    "      return (correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 is start\n",
      "Accuracy of Test Data: 9.545272827148438,  loss: 2.3543379306793213\n",
      "Accuracy of Test Data: 81.31009674072266,  loss: 0.9792035818099976\n",
      "Accuracy of Test Data: 93.79006958007812,  loss: 0.3668990731239319\n",
      "Accuracy of Test Data: 95.60296630859375,  loss: 0.09615117311477661\n",
      "Accuracy of Test Data: 96.56449890136719,  loss: 0.1279456615447998\n",
      "Accuracy of Test Data: 96.7147445678711,  loss: 0.031309157609939575\n",
      "Accuracy of Test Data: 97.09535217285156,  loss: 0.05474652722477913\n",
      "Accuracy of Test Data: 97.23558044433594,  loss: 0.08078088611364365\n",
      "Accuracy of Test Data: 97.4258804321289,  loss: 0.11123421043157578\n",
      "Accuracy of Test Data: 97.59615325927734,  loss: 0.09013378620147705\n",
      "Accuracy of Test Data: 97.68629455566406,  loss: 0.10262656211853027\n",
      "Accuracy of Test Data: 97.89663696289062,  loss: 0.05466841906309128\n",
      "Accuracy of Test Data: 97.29566955566406,  loss: 0.09287279844284058\n",
      "Accuracy of Test Data: 97.93669891357422,  loss: 0.02251037023961544\n",
      "Accuracy of Test Data: 97.52604675292969,  loss: 0.1392476111650467\n",
      "epoch 1 is start\n",
      "Accuracy of Test Data: 98.11698913574219,  loss: 0.027161359786987305\n",
      "Accuracy of Test Data: 98.32732391357422,  loss: 0.01920314133167267\n",
      "Accuracy of Test Data: 98.41746520996094,  loss: 0.03959031403064728\n",
      "Accuracy of Test Data: 98.53765869140625,  loss: 0.027818867936730385\n",
      "Accuracy of Test Data: 98.02684020996094,  loss: 0.07637105882167816\n",
      "Accuracy of Test Data: 98.26722717285156,  loss: 0.004281491972506046\n",
      "Accuracy of Test Data: 98.40745544433594,  loss: 0.13066436350345612\n",
      "Accuracy of Test Data: 98.41746520996094,  loss: 0.10168721526861191\n",
      "Accuracy of Test Data: 98.09695434570312,  loss: 0.02118922770023346\n",
      "Accuracy of Test Data: 98.32732391357422,  loss: 0.02660842053592205\n",
      "Accuracy of Test Data: 98.56771087646484,  loss: 0.04974538832902908\n",
      "Accuracy of Test Data: 98.11698913574219,  loss: 0.05222202464938164\n",
      "Accuracy of Test Data: 98.21714782714844,  loss: 0.046364229172468185\n",
      "Accuracy of Test Data: 98.45753479003906,  loss: 0.003982926718890667\n",
      "Accuracy of Test Data: 98.58773803710938,  loss: 0.07236987352371216\n",
      "epoch 2 is start\n",
      "Accuracy of Test Data: 98.49759674072266,  loss: 0.0037386086769402027\n",
      "Accuracy of Test Data: 98.5977554321289,  loss: 0.01667303405702114\n",
      "Accuracy of Test Data: 98.40745544433594,  loss: 0.002279214095324278\n",
      "Accuracy of Test Data: 98.73798370361328,  loss: 0.009419756941497326\n",
      "Accuracy of Test Data: 98.68789672851562,  loss: 0.09223946928977966\n",
      "Accuracy of Test Data: 98.51762390136719,  loss: 0.03038894198834896\n",
      "Accuracy of Test Data: 99.03846740722656,  loss: 0.006631733383983374\n",
      "Accuracy of Test Data: 98.52764892578125,  loss: 0.00215447717346251\n",
      "Accuracy of Test Data: 98.76802825927734,  loss: 0.024620387703180313\n",
      "Accuracy of Test Data: 98.51762390136719,  loss: 0.012881722301244736\n",
      "Accuracy of Test Data: 98.76802825927734,  loss: 0.0025725141167640686\n",
      "Accuracy of Test Data: 98.67788696289062,  loss: 0.10106031596660614\n",
      "Accuracy of Test Data: 98.90824890136719,  loss: 0.07471845299005508\n",
      "Accuracy of Test Data: 98.71794891357422,  loss: 0.027348162606358528\n",
      "Accuracy of Test Data: 98.51762390136719,  loss: 0.005182323511689901\n",
      "epoch 3 is start\n",
      "Accuracy of Test Data: 98.95833587646484,  loss: 0.19488674402236938\n",
      "Accuracy of Test Data: 98.25721740722656,  loss: 0.003491962794214487\n",
      "Accuracy of Test Data: 98.92828369140625,  loss: 0.03777113929390907\n",
      "Accuracy of Test Data: 98.44751739501953,  loss: 0.06780526041984558\n",
      "Accuracy of Test Data: 98.6278076171875,  loss: 0.007922656834125519\n",
      "Accuracy of Test Data: 99.07852172851562,  loss: 0.0841113030910492\n",
      "Accuracy of Test Data: 98.828125,  loss: 0.006620925851166248\n",
      "Accuracy of Test Data: 98.88822174072266,  loss: 0.05373624712228775\n",
      "Accuracy of Test Data: 99.00841522216797,  loss: 0.003972675651311874\n",
      "Accuracy of Test Data: 98.88822174072266,  loss: 0.14505422115325928\n",
      "Accuracy of Test Data: 98.70793151855469,  loss: 0.0033175365533679724\n",
      "Accuracy of Test Data: 98.77804565429688,  loss: 0.0011816140031442046\n",
      "Accuracy of Test Data: 98.74800109863281,  loss: 0.002643751911818981\n",
      "Accuracy of Test Data: 98.9883804321289,  loss: 0.007469662930816412\n",
      "Accuracy of Test Data: 98.86819458007812,  loss: 0.00040700280806049705\n",
      "epoch 4 is start\n",
      "Accuracy of Test Data: 98.73798370361328,  loss: 0.0020673659164458513\n",
      "Accuracy of Test Data: 98.88822174072266,  loss: 0.0019878908060491085\n",
      "Accuracy of Test Data: 98.99839782714844,  loss: 0.0005249781534075737\n",
      "Accuracy of Test Data: 98.828125,  loss: 0.013030490837991238\n",
      "Accuracy of Test Data: 99.16867065429688,  loss: 0.005385734140872955\n",
      "Accuracy of Test Data: 98.91827392578125,  loss: 0.015788903459906578\n",
      "Accuracy of Test Data: 98.70793151855469,  loss: 0.0014784400118514895\n",
      "Accuracy of Test Data: 99.06851196289062,  loss: 0.0030739163048565388\n",
      "Accuracy of Test Data: 99.00841522216797,  loss: 0.17941661179065704\n",
      "Accuracy of Test Data: 98.96835327148438,  loss: 0.004736399278044701\n",
      "Accuracy of Test Data: 99.09855651855469,  loss: 0.022134633734822273\n",
      "Accuracy of Test Data: 98.92828369140625,  loss: 0.045846957713365555\n",
      "Accuracy of Test Data: 98.94831848144531,  loss: 0.014088939875364304\n",
      "Accuracy of Test Data: 98.91827392578125,  loss: 0.2005496472120285\n",
      "Accuracy of Test Data: 98.96835327148438,  loss: 0.07973316311836243\n",
      "epoch 5 is start\n",
      "Accuracy of Test Data: 99.03846740722656,  loss: 0.0009958395967260003\n",
      "Accuracy of Test Data: 98.95833587646484,  loss: 0.016186609864234924\n",
      "Accuracy of Test Data: 99.18870544433594,  loss: 0.0004647015011869371\n",
      "Accuracy of Test Data: 99.25881958007812,  loss: 0.0007047845865599811\n",
      "Accuracy of Test Data: 99.0284423828125,  loss: 0.0010306909680366516\n",
      "Accuracy of Test Data: 99.0284423828125,  loss: 0.0005106827011331916\n",
      "Accuracy of Test Data: 98.95833587646484,  loss: 0.009539447724819183\n",
      "Accuracy of Test Data: 99.04847717285156,  loss: 0.01326737180352211\n",
      "Accuracy of Test Data: 98.96835327148438,  loss: 0.180487722158432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m ((j \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m test_model_flag \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m (j \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)):\n\u001b[1;32m     15\u001b[0m     loss_array\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m---> 16\u001b[0m     aa \u001b[39m=\u001b[39m get_accuracy()\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy of Test Data: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m100\u001b[39m\u001b[39m*\u001b[39maa), end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m), \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(loss_array[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     18\u001b[0m     accuracy_array\u001b[39m.\u001b[39mappend(aa\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[106], line 10\u001b[0m, in \u001b[0;36mget_accuracy\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m x \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m y_ \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m     11\u001b[0m _, output_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(output, \u001b[39m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m label\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[92], line 37\u001b[0m, in \u001b[0;36mResCRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m     36\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m---> 37\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2_x(output)\n\u001b[1;32m     38\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3_x(output)\n\u001b[1;32m     39\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_pool(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[103], line 29\u001b[0m, in \u001b[0;36mBottleNeck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresidual_function(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut(x)\n\u001b[1;32m     30\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    149\u001b[0m     \u001b[39m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_batches_tracked\u001b[39m.\u001b[39;49madd_(\u001b[39m1\u001b[39;49m)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    153\u001b[0m             exponential_average_factor \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_datas = train_test if test_model_flag is True else train_loader\n",
    "for i in range(num_epoch):\n",
    "    print(\"epoch\", i, \"is start\")\n",
    "    for j, [img, label] in enumerate(train_datas):\n",
    "        x = img.to(device)\n",
    "        y_ = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output= model.forward(x)\n",
    "        loss = loss_func(output, y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ((j == 0) if test_model_flag is True else (j % 100 == 0)):\n",
    "            loss_array.append(loss.detach().cpu().numpy())\n",
    "            aa = get_accuracy()\n",
    "            print(\"Accuracy of Test Data: {}, \".format(100*aa), end=\" \"), print(\"loss: {}\".format(loss_array[-1]))\n",
    "            accuracy_array.append(aa.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(len(accuracy_array))), accuracy_array[:])\n",
    "plt.plot(loss_array[:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
